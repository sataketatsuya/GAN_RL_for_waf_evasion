from .waf_label_env import WafLabelEnv
from .interfaces import LibinjectionInterface
import os
import binascii
import requests
import times
import random
import const

import torch
from torch.autograd import Variable
from discriminator.discriminator import Discriminator
from transformers import BertTokenizer


class LibinjectionEnv(WafLabelEnv):
    def __init__(self, payloads_file, csic_file, maxturns=20):
        super().__init__(payloads_file, csic_file, maxturns=maxturns)
        self.interface = LibinjectionInterface()

        # Loss function
        self.adversarial_loss = torch.nn.BCELoss() # Binary Cross Entropy Loss
        
        # Tokenizer
        self.tokenizer = BertTokenizer.from_pretrained(const.PRETRAINED_MODEL)
        
        # Discriminator
        self.discriminator = Discriminator(const.PRETRAINED_MODEL, const.DROP_OUT)
        
        # if os.path.exists('./models/dicriminator.pth'):
        #     self.discriminator.load_state_dict(torch.load('./models/dicriminator.pth'))

        # Optimizer
        self.optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=const.D_LR)

        self.cuda = torch.cuda.is_available()
        self.device = torch.device("cuda" if self.cuda else "cpu")

        if self.cuda:
            self.adversarial_loss.to(self.device)
            self.discriminator.to(self.device)

        self.batch_real_output = []
        self.batch_fake_output = []
        
        # This logger will help us with printing out summaries of each iteration
        self.logger = {
            'discriminator_losses': [],     # losses of discriminator's prediction in current iteration
        }

    def _get_label_waf(self, payload):
        payload = const.BASE_URL + '?id=' + payload
        result = requests.get(payload)

        return result.status_code == 200
        # return self.interface.get_label(payload)

    def _get_real_traffic(self): # get a real traffic randomly from HTTP DATASET CSIC 2010
        return random.choice(self.csic_http_traffic_list)

    def _get_fake_traffic(self, fake_payload):
        j_session_id = str(binascii.b2a_hex(os.urandom(16)).upper())[2:-1]
        fake_traffic = 'Type:Normal,Method:GET,User-Agent:Mozilla/5.0 (compatible; Konqueror/3.5; Linux) KHTML/3.5.8 (like Gecko),Pragma:no-cache,Cache-Control:no-cache,Accept:text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5,Accept-encoding:x-gzip, x-deflate, gzip, deflate,Accept-charset:utf-8, utf-8;q=0.5, *;q=0.5,language:en,host:localhost:8080,cookie:JSESSIONID={},content-type:nan,connection:close,lenght:nan,content:nan,classification:0,URL:{} HTTP/1.1'.format(j_session_id, fake_payload)

        return fake_traffic

    def _get_score_discriminator(self, fake_payload):
        # Get http traffic
        real_traffic = self._get_real_traffic()
        fake_traffic = self._get_fake_traffic(fake_payload)

        # Score real traffic by Discriminator
        real_input = self.tokenizer(real_traffic, padding='max_length', max_length=const.MAX_TOKEN_LENGTH, truncation=True, return_tensors="pt")
        real_input_ids = real_input['input_ids'].to(self.device)
        real_attention_mask = real_input['attention_mask'].to(self.device)
        real_output = self.discriminator(real_input_ids, real_attention_mask)
        self.batch_real_output.append(real_output.cpu().detach().numpy())

        # Score fake traffic by Discriminator which is generated by agent (Generator)
        fake_input = self.tokenizer(fake_traffic, padding='max_length', max_length=const.MAX_TOKEN_LENGTH, truncation=True, return_tensors="pt")
        fake_input_ids = fake_input['input_ids'].to(self.device)
        fake_attention_mask = fake_input['attention_mask'].to(self.device)
        fake_output = self.discriminator(fake_input_ids, fake_attention_mask)
        self.batch_fake_output.append(fake_output.cpu().detach().numpy())

        return fake_output.squeeze().cpu().detach().item()

    def update_discriminator(self):
        real_output = torch.tensor(self.batch_real_output, device=self.device, dtype=torch.float) # torch.Size([batch_size, 1, 1])
        fake_output = torch.tensor(self.batch_fake_output, device=self.device, dtype=torch.float) # torch.Size([batch_size, 1, 1])

        Tensor = torch.cuda.FloatTensor if self.cuda else torch.FloatTensor
        valid = Variable(Tensor(len(self.batch_real_output), 1, 1).fill_(1.0), requires_grad=True) # torch.Size([batch_size, 1, 1])
        fake = Variable(Tensor(len(self.batch_fake_output), 1, 1).fill_(0.0), requires_grad=True) # torch.Size([batch_size, 1, 1])

        # Caluculate losses
        real_loss = self.adversarial_loss(real_output, valid)
        fake_loss = self.adversarial_loss(fake_output, fake)
        d_loss = (real_loss + fake_loss) / 2

        # Calculate gradients and perform backward propagation for Discriminator network
        self.optimizer.zero_grad()
        d_loss.backward()
        self.optimizer.step()
        
        self.batch_real_output = []
        self.batch_fake_output = []
        
        # Log actor loss
        self.logger['discriminator_losses'].append(d_loss.cpu().detach())
